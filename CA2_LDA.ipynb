{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA2-LDA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i83UNcUNiLa",
        "colab_type": "text"
      },
      "source": [
        "# **Text Classification using LDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmRG4_GzrNqa",
        "colab_type": "text"
      },
      "source": [
        "We do this task by taking a topic modeling approach. topic modeling offers approach to organize, scan and synthesize large datasets. In this notebook we build the classifier that uses word counts as a feature to  decodes the similarities between the word counts. the algorithm we use is latent Dirichlet Allocation. LDA is a statistical model which aim is to discover topics that belong to the document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqoESnjNPf4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6728a62-dffd-459c-be49-f24f87d10539"
      },
      "source": [
        "#we load and store our dataset using pandas which is consisting of 200000 rows that means this data contains 200000 questions\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "dataframe = pd.read_csv('quora_questions.csv', nrows=200000)\n",
        "dataframe.columns = [\"questions\"]\n",
        "print('We have',len(dataframe), 'questions in the data')\n",
        "\n",
        "\n"
      ],
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 200000 questions in the data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W8rrUEtd14q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "fe730a4e-4646-40ee-a4b7-15e053cbbe2e"
      },
      "source": [
        "a = 100\n",
        "for i in range(a,a+10):\n",
        "    print(dataframe.questions[i])\n",
        "    print()"
      ],
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Will there really be any war between India and Pakistan over the Uri attack? What will be its effects?\n",
            "\n",
            "Did Ronald Reagan have a mannerism in his speech?\n",
            "\n",
            "What were the war strategies of the Union and the Confederates during the Civil War?\n",
            "\n",
            "Which is the best fiction novel of 2016?\n",
            "\n",
            "Can I recover my email if I forgot the password?\n",
            "\n",
            "Will the recent demonetisation results in higher GDP? If so how much?\n",
            "\n",
            "Have you ever heard of travel hacking?\n",
            "\n",
            "What's the difference between love and pity?\n",
            "\n",
            "How competitive is the hiring process at Republic Bank?\n",
            "\n",
            "How Google helps in spam ranking adjustment of the search results?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfL0CeGci1WX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3008556d-b2fc-4664-b30d-e9257a794284"
      },
      "source": [
        "dataframe.head()"
      ],
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           questions\n",
              "0  What is the step by step guide to invest in sh...\n",
              "1  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
              "2  How can I increase the speed of my internet co...\n",
              "3  Why am I mentally very lonely? How can I solve...\n",
              "4  Which one dissolve in water quikly sugar, salt..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB0rKsuBw-uC",
        "colab_type": "text"
      },
      "source": [
        "we use sklearn library named countvectorizer which is used to eliminate the common words in our document so that we cannot get words with high number of frequency. this step is the part of preprocessing of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dppaa1RMgG7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF6N5t9xy_ft",
        "colab_type": "text"
      },
      "source": [
        "For creating a vectorizer we need two parameters max_df and min_df that shows the numbers of words we ignore in document. purpose of min-df is to ignore the words that have very few occurences in the document. we use min value 2 which means that it eliminate words that appeared in less than 2 documents. as like min-df in max-df we ignore words that are too common in the document. we use 0.95 that means we ignored words that appeared 95% in the document. we also remove stop words by using stop_words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OGJwVk7gLN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vectorizer = CountVectorizer(min_df=2, stop_words=\"english\", max_df=0.95)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plkyBUGT2H2V",
        "colab_type": "text"
      },
      "source": [
        "we use fit_transform to calculate the parameters and trasform data to create sparse matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFJm78POghR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_term_matrix = count_vectorizer.fit_transform(dataframe['questions'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh0yfmKlghas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "23b82a26-7681-4569-b75b-8b4e358f3f85"
      },
      "source": [
        "doc_term_matrix #contains 200000 articles and 27884 words"
      ],
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<200000x27884 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 981746 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNndpZMzghd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation #we import LDA model from sklearn library"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0NjFeaR5NCY",
        "colab_type": "text"
      },
      "source": [
        "we build a LDA MODEL by using Latent class to create topics along with probability distribution. in this n_components parameter divided our text into number of categories that we want. random_state used to inititialize random number generator. in start we use 10 to see"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtMDy7YCghhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda = LatentDirichletAllocation(n_components=10,random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63omGC9w4Msv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "16eac905-b36f-4d6c-d94e-7ccff7c87674"
      },
      "source": [
        "lda.fit(doc_term_matrix)#for learning the projection matrix"
      ],
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
              "                          evaluate_every=-1, learning_decay=0.7,\n",
              "                          learning_method='batch', learning_offset=10.0,\n",
              "                          max_doc_update_iter=100, max_iter=10,\n",
              "                          mean_change_tol=0.001, n_components=10, n_jobs=None,\n",
              "                          perp_tol=0.1, random_state=1, topic_word_prior=None,\n",
              "                          total_samples=1000000.0, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 360
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XMWjB5P8Hhd",
        "colab_type": "text"
      },
      "source": [
        "we derive likelihood and perplexity in order to estimate the performance of our model. likelihood calculate the probability of observed data and perplexity used for quality of the model that how well model predicting. these can be measured by the criteria that likelihood is better when higher the value and perplexity is better when its value is low."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTiEi9lx5x5g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca20059e-b47e-46dc-ee96-e21ebe9fbfe3"
      },
      "source": [
        "print(\"Log Likelihood: \", lda.score(doc_term_matrix))"
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log Likelihood:  -8509084.295125658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3jcnYCe6MlD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "980396e2-0767-4b9d-c5a5-3b259fd493ce"
      },
      "source": [
        "print(\"Perplexity: \", lda.perplexity(doc_term_matrix))"
      ],
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perplexity:  4577.806873046729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rErjUSlwEI2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrCXKVzl9hUV",
        "colab_type": "text"
      },
      "source": [
        "**World Vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zunNh4WPmU7K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d19d8b8-4240-4417-9e4f-4f414763fef0"
      },
      "source": [
        "len(count_vectorizer.get_feature_names())#we use len to see the length of word list that stored in count_vectorizer"
      ],
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27884"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAZLQH-SmYdw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00985532-9528-48c6-e1b0-1f6700d74d46"
      },
      "source": [
        "count_vectorizer.get_feature_names()[610]"
      ],
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'484'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07yPgD9tmfRi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "72693e9a-32a8-4a4b-c768-74cc16ed1d33"
      },
      "source": [
        "lda.components_"
      ],
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.15054241e+01, 1.76760456e-01, 1.00000001e-01, ...,\n",
              "        1.00000000e-01, 3.09998705e+00, 1.00000000e-01],\n",
              "       [2.54817362e+00, 3.69781128e+02, 1.00118556e-01, ...,\n",
              "        1.00000000e-01, 1.00012946e-01, 1.00000000e-01],\n",
              "       [1.00044631e-01, 1.23420584e+01, 1.00000001e-01, ...,\n",
              "        1.00000000e-01, 1.00000000e-01, 1.00000000e-01],\n",
              "       ...,\n",
              "       [1.00004729e-01, 1.00003751e-01, 1.00000001e-01, ...,\n",
              "        1.00000000e-01, 1.00000000e-01, 1.00000000e-01],\n",
              "       [2.46309533e-01, 1.00004442e-01, 1.00000001e-01, ...,\n",
              "        1.00000000e-01, 1.00000000e-01, 1.00000801e-01],\n",
              "       [1.00001356e-01, 1.00021371e-01, 1.00000001e-01, ...,\n",
              "        2.10000000e+00, 1.00000000e-01, 5.09999888e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMECh5ZomgkB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6a5704b-a31f-4a3f-e656-b0e6ecea6dce"
      },
      "source": [
        "lda.components_.shape# this lda component contains the probabilty of each word we can see it by using index"
      ],
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 27884)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpH9QlhkmgvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_topic = lda.components_[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ8yHmAVmjjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb7c2d79-5268-47a4-ce97-ef0d2ae3fbf5"
      },
      "source": [
        "first_topic.argsort()#to see the all probabilities of words"
      ],
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  910, 26915, 10865, ..., 18522, 14630, 14032])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 369
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzVfBzX-mjrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DgB89oNCZIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "f985935a-849e-4a50-88c1-87f835529f3e"
      },
      "source": [
        "#we created a loop to show the top numbers of words of eaech topic\n",
        "word_list = []\n",
        "probability_list =[]\n",
        "\n",
        "top_number = 20\n",
        "topic_count = 0\n",
        "\n",
        "for probability_number in lda.components_:\n",
        "    text_message = f'Top words for topic {topic_count} are : '\n",
        "    print(text_message)\n",
        "    \n",
        "    for number in probability_number.argsort()[-top_number:]:\n",
        "        print([count_vectorizer.get_feature_names()[number]], end='')\n",
        "        \n",
        "        probability_list.append(number)\n",
        "    print('\\n')\n",
        "    topic_count+=1"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top words for topic 0 are : \n",
            "['love']['guy']['stop']['earth']['going']['difference']['read']['new']['year']['don']['old']['day']['best']['books']['things']['girl']['does']['people']['like']['know']\n",
            "\n",
            "Top words for topic 1 are : \n",
            "['laptop']['download']['tv']['favorite']['did']['watch']['mobile']['free']['energy']['buy']['iphone']['does']['app']['android']['movies']['new']['movie']['phone']['make']['best']\n",
            "\n",
            "Top words for topic 2 are : \n",
            "['good']['writing']['skills']['think']['salary']['black']['modi']['rupee']['money']['government']['2016']['english']['rs']['prepare']['improve']['1000']['500']['notes']['indian']['india']\n",
            "\n",
            "Top words for topic 3 are : \n",
            "['data']['earn']['learning']['company']['computer']['programming']['like']['business']['way']['india']['language']['make']['start']['engineering']['job']['good']['online']['money']['learn']['best']\n",
            "\n",
            "Top words for topic 4 are : \n",
            "['suicide']['snapchat']['thing']['like']['sentence']['real']['die']['people']['purpose']['bad']['does']['china']['write']['way']['increase']['whatsapp']['did']['com']['used']['life']\n",
            "\n",
            "Top words for topic 5 are : \n",
            "['hack']['pakistan']['education']['happen']['worst']['hotel']['thing']['major']['effects']['police']['gmail']['email']['safe']['war']['password']['india']['instagram']['account']['examples']['facebook']\n",
            "\n",
            "Top words for topic 6 are : \n",
            "['girlfriend']['california']['visa']['hate']['space']['good']['god']['change']['visit']['places']['bank']['number']['travel']['think']['possible']['card']['people']['way']['time']['best']\n",
            "\n",
            "Top words for topic 7 are : \n",
            "['election']['long']['food']['did']['win']['question']['questions']['hillary']['clinton']['like']['president']['feel']['people']['google']['donald']['work']['mean']['trump']['quora']['does']\n",
            "\n",
            "Top words for topic 8 are : \n",
            "['considered']['days']['period']['difference']['good']['like']['white']['way']['ways']['use']['girls']['did']['indian']['men']['black']['does']['math']['women']['lose']['weight']\n",
            "\n",
            "Top words for topic 9 are : \n",
            "['sex']['meaning']['class']['word']['relationship']['big']['ask']['war']['social']['true']['start']['important']['quora']['questions']['country']['people']['did']['love']['does']['world']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9EoUWRImjm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "8096d989-be9c-403a-9d1d-8c052f711605"
      },
      "source": [
        "#by using for loop we see the 20 words of each topic we can increase it by increasing the value of top_number\n",
        "top_number = 20\n",
        "count = 0\n",
        "for probability_number in lda.components_:\n",
        "    print(f\"Top words for topic {count} are : \")    \n",
        "    for number in probability_number.argsort()[-top_number:]:\n",
        "        print([count_vectorizer.get_feature_names()[number]], end= \"\")\n",
        "    print(\"\\n\")\n",
        "    count += 1"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top words for topic 0 are : \n",
            "['love']['guy']['stop']['earth']['going']['difference']['read']['new']['year']['don']['old']['day']['best']['books']['things']['girl']['does']['people']['like']['know']\n",
            "\n",
            "Top words for topic 1 are : \n",
            "['laptop']['download']['tv']['favorite']['did']['watch']['mobile']['free']['energy']['buy']['iphone']['does']['app']['android']['movies']['new']['movie']['phone']['make']['best']\n",
            "\n",
            "Top words for topic 2 are : \n",
            "['good']['writing']['skills']['think']['salary']['black']['modi']['rupee']['money']['government']['2016']['english']['rs']['prepare']['improve']['1000']['500']['notes']['indian']['india']\n",
            "\n",
            "Top words for topic 3 are : \n",
            "['data']['earn']['learning']['company']['computer']['programming']['like']['business']['way']['india']['language']['make']['start']['engineering']['job']['good']['online']['money']['learn']['best']\n",
            "\n",
            "Top words for topic 4 are : \n",
            "['suicide']['snapchat']['thing']['like']['sentence']['real']['die']['people']['purpose']['bad']['does']['china']['write']['way']['increase']['whatsapp']['did']['com']['used']['life']\n",
            "\n",
            "Top words for topic 5 are : \n",
            "['hack']['pakistan']['education']['happen']['worst']['hotel']['thing']['major']['effects']['police']['gmail']['email']['safe']['war']['password']['india']['instagram']['account']['examples']['facebook']\n",
            "\n",
            "Top words for topic 6 are : \n",
            "['girlfriend']['california']['visa']['hate']['space']['good']['god']['change']['visit']['places']['bank']['number']['travel']['think']['possible']['card']['people']['way']['time']['best']\n",
            "\n",
            "Top words for topic 7 are : \n",
            "['election']['long']['food']['did']['win']['question']['questions']['hillary']['clinton']['like']['president']['feel']['people']['google']['donald']['work']['mean']['trump']['quora']['does']\n",
            "\n",
            "Top words for topic 8 are : \n",
            "['considered']['days']['period']['difference']['good']['like']['white']['way']['ways']['use']['girls']['did']['indian']['men']['black']['does']['math']['women']['lose']['weight']\n",
            "\n",
            "Top words for topic 9 are : \n",
            "['sex']['meaning']['class']['word']['relationship']['big']['ask']['war']['social']['true']['start']['important']['quora']['questions']['country']['people']['did']['love']['does']['world']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06ULAwwRAxRV",
        "colab_type": "text"
      },
      "source": [
        "as we can see from above records that topic 7 is realted to Politics, Law, Government, and Judiciary. now we add the relavent topic number to the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "116vN8annj6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textfile_topics = lda.transform(doc_term_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX2Nh-ODnsxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91556138-e904-4895-e353-c8a8a339f8f4"
      },
      "source": [
        "textfile_topics[0].round(2)"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01, 0.01, 0.89, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwXSpHYMnwqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb0dbea6-ac46-4869-a31b-f3571f59e59f"
      },
      "source": [
        "textfile_topics[0].argmax()"
      ],
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn7XFxh0nywY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "examined_topic = lda.components_[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRF1E55Nn3ZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "aaa0d9fe-6930-4345-c56b-eb5538a34cf8"
      },
      "source": [
        "# Show more words for better topic selection for this topic (2)\n",
        "for index in examined_topic.argsort()[-50:]:\n",
        "    print(count_vectorizer.get_feature_names()[index], end=\" \")"
      ],
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "real prime narendra does stock rupees affect pro indians gate invest foreign marks cat jee iit decision help 2017 note banning ban market exam currency 2000 score new difference economy good writing skills think salary black modi rupee money government 2016 english rs prepare improve 1000 500 notes indian india "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufLFSpVdqexn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_list = []\n",
        "# Textfile_topics is a list of arrays containing \n",
        "# all index positions of words for each textfile\n",
        "for popular_index_pos in textfile_topics:\n",
        "    # Get the max index position in each array\n",
        "    # and add to the topic_list list\n",
        "    topic_list.append(popular_index_pos.argmax())\n",
        "\n",
        "# Add a new column to the dataframe\n",
        "dataframe[\"Topic number\"] = topic_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtQNOxW-qerz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f19e9321-af45-4d85-b325-1fba0cbb88fb"
      },
      "source": [
        "dataframe\n",
        "\n"
      ],
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "      <th>Topic number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>Why was the Battle of Vimy Ridge so important?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>Which of these TV shows should I watch next?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>Should I change my name?</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>Should I buy the new MacBook 2016 or one from ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>What is your review of Love (2011 movie)?</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                questions  Topic number\n",
              "0       What is the step by step guide to invest in sh...             2\n",
              "1       What is the story of Kohinoor (Koh-i-Noor) Dia...             0\n",
              "2       How can I increase the speed of my internet co...             5\n",
              "3       Why am I mentally very lonely? How can I solve...             7\n",
              "4       Which one dissolve in water quikly sugar, salt...             1\n",
              "...                                                   ...           ...\n",
              "199995     Why was the Battle of Vimy Ridge so important?             1\n",
              "199996       Which of these TV shows should I watch next?             1\n",
              "199997                           Should I change my name?             6\n",
              "199998  Should I buy the new MacBook 2016 or one from ...             2\n",
              "199999          What is your review of Love (2011 movie)?             5\n",
              "\n",
              "[200000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 378
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lmltZy_rxnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_list = {0: \"Art, Design, and Style\", \n",
        "              1: \"Humanities\", \n",
        "              2: \"Life, Relationships, and Self\", \n",
        "              3: \"Business, Work, and Careers\", \n",
        "              4: \"Recreation, Sports, Travel, and Activities\", \n",
        "              5: \"Science, Technology, Engineering, and Mathematics\", \n",
        "              6: \"horoscopes\", \n",
        "              7: \"Politics, Law, Government, and Judiciary\", \n",
        "              8: \"Literature, Languages, and Communication\", \n",
        "              9: \"Medicine and Healthcare\", \n",
        "            }\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p62tRFzruEb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_no_to_topic = dataframe[\"Topic number\"].map(topic_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUqy4KN2uQDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dataframe[\"Topic desc\"] = topic_no_to_topic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvXW0eBkuJdY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "f81c5525-c006-4697-9753-140ec98bc4bf"
      },
      "source": [
        "dataframe.head(10)"
      ],
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "      <th>Topic number</th>\n",
              "      <th>Topic desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>2</td>\n",
              "      <td>Life, Relationships, and Self</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>0</td>\n",
              "      <td>Art, Design, and Style</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>5</td>\n",
              "      <td>Science, Technology, Engineering, and Mathematics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>7</td>\n",
              "      <td>Politics, Law, Government, and Judiciary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>1</td>\n",
              "      <td>Humanities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>5</td>\n",
              "      <td>Science, Technology, Engineering, and Mathematics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>1</td>\n",
              "      <td>Humanities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>3</td>\n",
              "      <td>Business, Work, and Careers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>When do you use ã‚· instead of ã—?</td>\n",
              "      <td>7</td>\n",
              "      <td>Politics, Law, Government, and Judiciary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
              "      <td>3</td>\n",
              "      <td>Business, Work, and Careers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           questions  ...                                         Topic desc\n",
              "0  What is the step by step guide to invest in sh...  ...                      Life, Relationships, and Self\n",
              "1  What is the story of Kohinoor (Koh-i-Noor) Dia...  ...                             Art, Design, and Style\n",
              "2  How can I increase the speed of my internet co...  ...  Science, Technology, Engineering, and Mathematics\n",
              "3  Why am I mentally very lonely? How can I solve...  ...           Politics, Law, Government, and Judiciary\n",
              "4  Which one dissolve in water quikly sugar, salt...  ...                                         Humanities\n",
              "5  Astrology: I am a Capricorn Sun Cap moon and c...  ...  Science, Technology, Engineering, and Mathematics\n",
              "6                                Should I buy tiago?  ...                                         Humanities\n",
              "7                     How can I be a good geologist?  ...                        Business, Work, and Careers\n",
              "8                When do you use ã‚· instead of ã—?  ...           Politics, Law, Government, and Judiciary\n",
              "9  Motorola (company): Can I hack my Charter Moto...  ...                        Business, Work, and Careers\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 382
        }
      ]
    }
  ]
}